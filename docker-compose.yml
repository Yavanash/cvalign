services:
  backend:
    build:
      context: ./backend
    ports:
      - "8080:8080"
    depends_on:
      - ml
    volumes:
      - uploads-data:/app/uploads
    extra_hosts:
      - "host.docker.internal:host-gateway"

  ml:
    build:
      context: .
      dockerfile: Dockerfile.fastapi
    ports:
      - "8000:8000"
    environment:
      - OLLAMA_BASE_URL=http://host.docker.internal:11434
    volumes:
      - uploads-data:/app/uploads
      - ./ml_logic/vector-store:/app/vector-store
    extra_hosts:
      - "host.docker.internal:host-gateway"

volumes:
  uploads-data:
